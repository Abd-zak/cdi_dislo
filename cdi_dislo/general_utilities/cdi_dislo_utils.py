"""
############################################################################################################
#                                    SCRIPT IMPROVEMENT NOTES                                              #
############################################################################################################

### 1. Code Optimization & Readability
# - Reduce `import *` usage; explicitly import required functions/classes.
# - Consolidate repeated imports at the top.
# - Replace `print()` with `logging.info()`, `logging.warning()`, etc., for better debugging.
# - Maintain a consistent function naming convention (`snake_case` preferred in Python).

### 2. Function-Level Improvements
# A. `extract_coefficient_and_exponent(number)`:
#    - Handle `number = 0` to avoid `log10(0)` error.
#    - Fix: Add a zero condition.

# B. `generate_burgers_directions(m, G, ...)`:
#    - Validate that `G != [0,0,0]` to prevent division errors.

# C. `find_max_and_com_3d(data, window_size=10)`:
#    - Ensure `data` is not all NaNs before calling `np.argmax(data)`.

# D. `normalize_vector(v)`:
#    - Prevent division by zero by adding a small epsilon.

### 3. Optimization of Large Functions
# - `crop_data_and_update_coordinates()`: Break into `compute_new_coordinates()`, `apply_padding()`, `crop_data()`, `validate_results()`.
# - `data_processing()`: Use NumPy vectorized operations instead of loops.

### 4. Handling Large Datasets Efficiently
# - Use `numpy.memmap` for large arrays instead of in-memory `np.array()`.
# - Implement multiprocessing with `multiprocessing.Pool()` for speed improvements.
# - Avoid modifying global arrays in-place; return new arrays instead.

### 5. Structural Improvements
# - Move utility functions (`normalize_vector()`, `check_array_empty()`, etc.) to `utilities.py` for reusability.
# - Group related functions into classes (e.g., `CroppingHandler` for cropping functions).

### 6. Final Checklist
# ✅ Avoid Redundant Imports
# ✅ Refactor Large Functions
# ✅ Improve Exception Handling
# ✅ Use Logging Instead of Print
# ✅ Consider Memory Optimization Techniques

############################################################################################################
#                                   END OF IMPROVEMENT NOTES                                              #
############################################################################################################
"""
"""
############################################################################################################
#                                    SCRIPT OVERVIEW                                                      #
############################################################################################################

# This script contains various utilities for processing 3D diffraction data, analyzing dislocations, 
# and handling BCDI (Bragg Coherent Diffraction Imaging) reconstructions. It includes functions for:
#
# 1. **Imports & Dependencies** 
#    - Imports essential libraries for scientific computing, image processing, and machine learning.
#    - Common imports (`cdi_dislo.common_imports`) include NumPy, SciPy, Matplotlib, and Sklearn.
#
# 2. **Mathematical & Utility Functions**
#    - `extract_coefficient_and_exponent()`: Extracts the coefficient and exponent from a number.
#    - `normalize_vector()`: Normalizes a given vector to unit length.
#    - `project_vector()`: Projects a vector onto a plane perpendicular to another vector.
#    - `rotation_matrix_from_angles()`: Computes a 3D rotation matrix from Euler angles.
#
# 3. **3D Data Processing & Cropping**
#    - `crop_data_and_update_coordinates()`: Crops 3D data and updates spatial coordinates accordingly.
#    - `crop_3d_obj_pos_and_update_coordinates()`: Crops a complex 3D object and recalculates coordinates.
#    - `fill_up_support()`: Fills holes inside a binary support mask.
#
# 4. **Dislocation & Burgers Vector Analysis**
#    - `generate_burgers_directions()`: Computes possible Burgers vector directions based on a reciprocal lattice vector.
#    - `get_dislocation_position()`: Identifies dislocation positions from a given mask.
#
# 5. **Statistical Analysis & Feature Extraction**
#    - `std_data()`: Computes the standard deviation of nonzero elements in a dataset.
#    - `mean_z_run()`, `mean_y_run()`, `mean_x_run()`: Computes mean values along different axes.
#    - `std_rho()`: Computes the standard deviation of density across multiple scans.
#
# 6. **Data Masking & Clustering**
#    - `mask_clusters()`: Identifies and masks clusters in 3D data.
#    - `get_largest_component()`: Extracts the largest connected component from a binary mask.
#
# 7. **BCDI Data Processing & Reconstruction Handling**
#    - `data_processing()`: Processes raw reconstruction data from multiple scans and extracts key parameters.
#    - `load_reco_from_cxinpz()`: Loads reconstruction data from `.cxi`, `.h5`, or `.npz` files.
#
# 8. **Regression & Machine Learning Utilities**
#    - `fit_model_regression()`: Fits various regression models (Linear, Decision Tree, SVR, MLP, etc.).
#
# 9. **Coordinate System Transformations**
#    - `transform_data_paraview_style()`: Rotates and transforms 3D data with a padding buffer to prevent cropping artifacts.
#
# 10. **Miscellaneous Functions**
#    - `check_array_empty()`: Checks whether a NumPy array is empty.
#    - `pad_to_shape()`: Pads an array to a given shape.
#    - `optimize_cropping()`: Determines the best cropping size for a dataset.
#
# 11. **Execution & Main Script Logic**
#    - The script does not currently contain a `main()` function but provides modular utilities 
#      that can be used independently or within larger pipelines.

############################################################################################################
#                                   END OF SCRIPT OVERVIEW                                                #
############################################################################################################
"""



from cdi_dislo.common_imports                                     import *
from cdi_dislo.plotutilities.cdi_dislo_plotutilities              import plotqxqyqzi_imshow
from cdi_dislo.orthogonalisation_handler.cdi_dislo_ortho_handler  import get_displacement_gradient

from cdi_dislo.ewen_utilities.plot_utilities                      import plot_3D_projections ,plot_2D_slices_middle_one_array3D
#####################################################################################################################
#####################################################################################################################
def extract_coefficient_and_exponent(number):
    # Extract the exponent
    exponent = int(math.log10(np.abs(number)))
    # Calculate the coefficient
    coefficient = number / (10 ** exponent)
    return coefficient, exponent
def transform_miller_indices(miller_list):
    transformed_list = []
    for indices in miller_list:
        transformed = []
        i = 0
        while i < len(indices):
            if indices[i] == '-':  # Handle negative numbers
                transformed.append(-int(indices[i+1]))
                i += 2  # Skip the next character since it's part of the negative number
            else:
                transformed.append(int(indices[i]))
                i += 1  # Move to the next character
        transformed_list.append(transformed)
    return array(transformed_list).astype(float)
def generate_burgers_directions(m, G, hkl_max=5, sort_by_hkl=True, angle_vector=None):
    """
    Generate all possible primitive Burgers vector directions [h, k, l] and their negatives [-h, -k, -l]
    for a given reciprocal lattice vector G, a specific integer m, removing redundant cases where b is 
    perpendicular to G.

    Parameters:
        m (int): Integer m to compute possible Burgers vectors. If m = 0, function returns an empty list.
        G (list or numpy array): Reciprocal lattice vector G = [Gx, Gy, Gz].
        hkl_max (int): Maximum np.absolute value for h, k, l components.
        sort_by_hkl (bool): If True, sort by h, k, l. If False, sort by angle.
        angle_vector (list or numpy array): Vector to compute angle with. If None, use G.

    Returns:
        list: List of tuples (direction, angle) where direction is [h, k, l] and angle is in degrees.
    """

    if m == 0:
        return []  # Skip m = 0 as it corresponds to invisible dislocations.

    def is_primitive_vector(vector):
        non_zero = [np.abs(x) for x in vector if x != 0]
        if not non_zero:
            return False
        common_divisor = reduce(gcd, non_zero)
        return common_divisor == 1

    def calculate_angle(v1, v2):
        """ Compute the angle between two vectors in degrees. """
        dot_product = sum(v1[i] * v2[i] for i in range(len(v1)))
        magnitude_v1 = sqrt(sum(x**2 for x in v1))
        magnitude_v2 = sqrt(sum(x**2 for x in v2))
        cos_theta = dot_product / (magnitude_v1 * magnitude_v2)
        cos_theta = max(-1.0, min(1.0, cos_theta))  # Ensure cos_theta is within [-1, 1]
        return degrees(acos(cos_theta))

    valid_directions = []
    seen_vectors = set()  # To track unique vectors before sorting
    angle_vector = angle_vector if angle_vector is not None else G

    for h in range(-hkl_max, hkl_max+1):
        for k in range(-hkl_max, hkl_max+1):
            for l in range(-hkl_max, hkl_max+1):
                if (h == 0 and k == 0 and l == 0):
                    continue  # Skip the zero vector

                dot_product = G[0] * h + G[1] * k + G[2] * l
                
                if dot_product == 0:
                    continue  # Skip invisible vectors

                if dot_product == 2 * m:
                    if is_primitive_vector([h, k, l]):
                        vector = tuple([h, k, l])
                        neg_vector = tuple([-h, -k, -l])

                        # Ensure we store both b and -b uniquely
                        for v in [vector, neg_vector]:
                            if v not in seen_vectors:
                                seen_vectors.add(v)
                                angle = calculate_angle(angle_vector, v)
                                valid_directions.append((list(v), angle))

    # Sorting improvements
    if sort_by_hkl:
        valid_directions.sort(key=lambda x: (x[0][0], x[0][1], x[0][2]))
    else:
        valid_directions.sort(key=lambda x: x[1])

    return valid_directions

# Normalize vector
def normalize_vector(v):
    norm = np.linalg.norm(v)
    return v / norm if norm > 1e-12 else v

# Project vector onto plane perpendicular to another vector
def project_vector(v, t):
    v = np.array(v, dtype=np.float64)  # Ensure `v` is a NumPy array
    t = np.array(t, dtype=np.float64)  # Ensure `t` is a NumPy array
    return v - (np.dot(v, t) / np.linalg.norm(t)**2) * t




def center_angles(angles):
    """
    Centers a list of angles between -max_angle and max_angle.

    Parameters:
        angles (list or np.ndarray): List of angles in degrees or radians.
        max_angle (float): Maximum angle for centering.

    Returns:
        np.ndarray: Angles centered between -max_angle and max_angle.
    """
    min_angle=np.nanmin(angles)
    # Convert angles to a numpy array for vectorized operations
    angles = np.array(angles)
    shift_tozero=(angles - min_angle)
    # Normalize angles to [-max_angle, max_angle]
    max_angle_new=(np.nanmax(shift_tozero))/2
    centered_angles = shift_tozero - max_angle_new
    
    return centered_angles


def find_max_and_com_3d(data, window_size=10):
    """
    Finds the position of the maximum value in a 3D array and computes the rounded center of mass (COM)
    within a window around the maximum.

    Parameters:
    - data: 3D numpy array.
    - window_size: Defines the region around the max for COM computation.

    Returns:
    - max_pos: (z, y, x) coordinates of the maximum value.
    - com_pos: (z, y, x) rounded center of mass.
    """
    data = np.array(data)

    # Find the coordinates of the maximum value
    max_pos = np.unravel_index(np.argmax(data), data.shape)

    # Define the window around the maximum
    z_min = max(0, max_pos[0] - window_size // 2)
    z_max = min(data.shape[0], max_pos[0] + window_size // 2 + 1)
    y_min = max(0, max_pos[1] - window_size // 2)
    y_max = min(data.shape[1], max_pos[1] + window_size // 2 + 1)
    x_min = max(0, max_pos[2] - window_size // 2)
    x_max = min(data.shape[2], max_pos[2] + window_size // 2 + 1)

    # Extract the sub-region around the max
    sub_region = data[z_min:z_max, y_min:y_max, x_min:x_max]

    # Compute the center of mass in the sub-region
    com_local = C_O_M(  sub_region)

    # Adjust COM coordinates to global positions and round them
    com_pos = (
        round(com_local[0] + z_min),
        round(com_local[1] + y_min),
        round(com_local[2] + x_min)
    )

    return max_pos, com_pos

def fill_up_support(support, plot=False):
    '''
    Modify the support by filling any hole inside.
    '''
    
    def process_axis(support, axis):
        support_cum = np.cumsum(support, axis=axis)
        support_cum_inv = np.flip(np.cumsum(np.flip(support, axis=axis), axis=axis), axis=axis)
        support_combine = support_cum * support_cum_inv
        return support_combine

    def fill_up_support_parallel(support):
        support_convex = np.zeros(support.shape)
        
        # Create remote tasks for each axis
        futures = [process_axis(support, axis) for axis in range(support.ndim)]
        
        # Get results
        results = futures
        
        # Combine results
        for result in results:
            support_convex[result != 0] = 1
        
        return support_convex

    support_convex = fill_up_support_parallel(support)

    if plot:
        plot_2D_slices_middle_one_array3D(support, cmap='gray_r', fig_title='original support')
        plot_2D_slices_middle_one_array3D(support_convex, cmap='gray_r', fig_title='filled support')

    return support_convex



# Function to apply centered affine transformation
def centered_affine_transform(data, rotation_matrix):
    """Applies a centered affine transformation to a 3D array."""
    shape = np.array(data.shape)
    center = (shape - 1) / 2  # Compute center of the volume

    # Create coordinate grid
    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')
    coords = np.stack((x, y, z), axis=-1).reshape(-1, 3)

    # Shift to center, apply rotation, and shift back
    coords_centered = coords - center
    rotated_coords = (rotation_matrix @ coords_centered.T).T + center

    # Interpolate values at the transformed coordinates
    transformed_data = map_coordinates(data, rotated_coords.T, order=1, mode='constant', cval=0)
    
    return transformed_data.reshape(shape)
# Function to create a rotation matrix from angles

def rotation_matrix_from_angles(angle_x, angle_y, angle_z):
    """Compute the 3D rotation matrix from given Euler angles (in degrees)."""
    angle_x, angle_y, angle_z = np.radians([angle_x, angle_y, angle_z])
    
    # Rotation matrices
    Rx = np.array([[1, 0, 0],
                   [0, np.cos(angle_x), -np.sin(angle_x)],
                   [0, np.sin(angle_x), np.cos(angle_x)]])
    
    Ry = np.array([[np.cos(angle_y), 0, np.sin(angle_y)],
                   [0, 1, 0],
                   [-np.sin(angle_y), 0, np.cos(angle_y)]])
    
    Rz = np.array([[np.cos(angle_z), -np.sin(angle_z), 0],
                   [np.sin(angle_z), np.cos(angle_z), 0],
                   [0, 0, 1]])
    
    # Combined rotation order: Z -> Y -> X
    R = Rx @ Ry @ Rz
    return R



def nan_to_zero(phase):
    return np.nan_to_num(phase, nan=0)
def format_as_4digit_string(number):
    return f"{number:04d}"

def isfloat(num):
    try:
        float(num)
        return True
    except ValueError:
        return False
def IfStringRepresentsFloat(x):
    for i in range(len(x)):
        #print(x[0:len(x)-i])
        if isfloat(x[0:len(x)-i]):  
            if float(x[0:len(x)-i])>10000: return 0.0
            else: return float(x[0:len(x)-i]) 
            break
#        else:
#            if isfloat(x[0:-1]):                return float(x[0:-1]) 
#            else: 
#                if isfloat(x[0:-2]):        return float(x[0:-2])
        else: 
            if i< len(x) : continue
            else:          return False
def check_array_empty(array__):
    """
    Check if a NumPy array is empty.

    Parameters:
    - array (numpy.ndarray): The array to check.

    Returns:
    - bool: True if the array is empty, False otherwise.
    """
    if array(array__).size == 0:
        return True
    else:
        return False
def array_to_dict(array):
  """Converts a NumPy array to a dictionary.

  Args:
    array: A NumPy array.

  Returns:
    A dictionary.
  """

  if array.dtype.names is None:
    array = array.flatten()
    dictionary = {}
    for index, value in enumerate(array):
      dictionary[index] = value
  else:
    dictionary = {}
    for key, value in zip(array.dtype.names, array.tolist()):
      dictionary[key] = value
  return dictionary    
def check_type(var):
    if isinstance(var, (list, tuple, np.ndarray)):
        if len(var) > 0:
            # Determine the type of elements
            all_int   = all([isinstance(item, (int, np.integer)) for item in var])
            all_float = all([isinstance(item, (float, np.floating)) for item in var])
            all_str   = all([isinstance(item, (str, np.str_)) for item in var])
            all_bool  = all([isinstance(item, (bool, np.bool_)) for item in var])
            
            if isinstance(var, np.ndarray):
                container_type = "array"
            else:
                container_type = type(var).__name__  # "list" or "tuple"
            
            # Identify the type of elements
            if all_int:
                element_type = "int"
            elif all_float:
                element_type = "float"
            elif all_str:
                element_type = "string"
            elif all_bool:
                element_type = "bool"
            else:
                element_type = "mixed"
            
            return f"{container_type} of {element_type}"
        else:
            return f"empty {type(var).__name__}"
    elif isinstance(var, (int, float, str, bool, np.integer, np.floating, np.str_, np.bool_)):
        return f"{type(var).__name__}"
    else:
        return "Unknown type"
def multiply_list_elements(arr):
    result = 1
    for num in arr:
        result *= num
    return result
# Define the DualOutput class for dual printing
class DualOutput:
    def __init__(self, *streams, log_only=False):
        self.streams = streams
        self.log_only = log_only  # If True, output only to the log file

    def write(self, message):
        if self.log_only:  # Output only to the last stream (assumed to be the log file)
            self.streams[-1].write(message)
            self.streams[-1].flush()
        else:  # Output to all streams
            for stream in self.streams:
                stream.write(message)
                stream.flush()  # Ensure immediate writing to output

    def flush(self):
        for stream in self.streams:
            stream.flush()
class Float(float):
    def __new__(cls, value):
        return float.__new__(cls, value)

    def __init__(self, value):
        self.value = Decimal(str(value))

    def __add__(self, other):
        return Float(self._operate(other, Decimal.__add__))

    def __sub__(self, other):
        return Float(self._operate(other, Decimal.__sub__))

    def __mul__(self, other):
        return Float(self._operate(other, Decimal.__mul__))

    def __truediv__(self, other):
        return Float(self._operate(other, Decimal.__truediv__))

    def _operate(self, other, operation):
        getcontext().prec = 4
        other_value = other.value if isinstance(other, Float) else Decimal(str(other))
        result = operation(self.value, other_value)
        return float(result)

    def __repr__(self):
        return f"{float(self.value):.4f}"
def get_numbers_from_string(string):
    """Extracts the numbers from a string in a professional way.

  Args:
    string: A string containing the numbers.

  Returns:
    A list of numbers, or an empty list if the string does not contain any numbers.
  """
    # Use regular expression to find all numbers in the string
    numbers = re.findall(r'\d+', string)
    # Concatenate the numbers into a single word
    result = ''.join(numbers)
    
    return result


def std_data(data):
    
    data= data.flatten()
    data=data[data!=0]
    mean_d= np.sum(data)/len(data)
    std= np.sqrt(np.square(data-mean_d).sum() /len(data) )
    return std

#####################################################################################################################
#####################################################################################################################
############################################crop & general utility ##################################################
#####################################################################################################################
##################################################################################################################### 
def remove_bordersurface_mask(mask,order=2):
    graadient_modes_mask=(np.max(nan_to_zero(np.abs(array(get_displacement_gradient((mask),voxel_size=(1,1,1))))),axis=0)!=0).astype(float)
    if order ==2:
        graadient_graadient_modes_mask=np.max(nan_to_zero(np.abs(array(get_displacement_gradient((graadient_modes_mask),voxel_size=(1,1,1))))),axis=0)!=0
        mask=(((graadient_modes_mask)*(graadient_graadient_modes_mask)-mask)<0).astype(float)    
    else:
        #print("order is one")
        mask=(((graadient_modes_mask)-mask)<0).astype(float)    

    return mask
def get_largest_component(binary_mask):
    """
    Finds and returns the largest connected component in a 3D binary mask.

    Parameters:
    - binary_mask: 3D numpy array (binary mask with values 0 and 1)

    Returns:
    - largest_component_mask: 3D numpy array with the same shape as `binary_mask`,
      where only the largest connected component is set to 1, and all other areas are 0.
    - max_label: the label of the largest component
    - max_size: the size of the largest component
    """
    # Label connected components in the binary mask
    labeled_mask, num_features = label(binary_mask)

    # Count occurrences of each label, ignoring background label 0
    label_sizes = np.bincount(labeled_mask.flatten())
    label_sizes[0] = 0  # Exclude background

    # Find the label with the maximum size
    max_label = np.argmax(label_sizes)
    max_size = label_sizes[max_label]

    # Create a new mask with only the largest component
    largest_component_mask = (labeled_mask == max_label).astype(int)

    return largest_component_mask, max_label, max_size
def crop_data_and_update_coordinates(x, y, z, data, finalshape, pos="com", k_add=20, verbose=True):
    # Get the original data shape
    orig_shape = np.array(data.shape)
    finalshape = np.array(finalshape)
    # Ensure pos and output_shape are numpy arrays for easier manipulation
    type_of_methods=check_type(pos)
    if type_of_methods=="str":      
        if pos=='max': pos_pad=('max',)
        elif pos=='com': pos_pad=('com',)
    elif ((type_of_methods=="array of float") or (type_of_methods=="array of int")):
            pos_pad=(tuple(pos),)
    elif ((type_of_methods=="list of float") or (type_of_methods=="list of int")):
            pos_pad=(tuple(pos),)
    elif "mixed" in type_of_methods:
        if (("list" in  type_of_methods) or ("array" in  type_of_methods) ):
            pos_pad=(tuple(pos),)    
    if (('max' in pos ) or ('com' in pos)):
        pos=array([int(np.round(i)) for i in C_O_M(data)])
    else:
        pos=pos
    k_add=10
    # Calculate padding
    pad_before = finalshape // 2 - pos 
    pad_after = np.maximum((pos + finalshape // 2 + finalshape % 2) - orig_shape, 0) + k_add
    pad_after=[i if i>0 else 0 for i in pad_after]
    pad_before=[i if i>0 else 0 for i in pad_before]
    # Pad the array
    padded_data = np.pad(data, list(zip(pad_before, pad_after)), mode='constant', constant_values=0)
    # Determine the position for cropping
            
    (
        crop_data_cdi,  # the output cropped data
        det_ref,  # the detector reference voxel in the full detector frame
        cropped_det_ref,  # the detector reference voxel in the cropped detector frame
        roi  # the region of interest (ROI) used to crop the data
    ) = chain_centring(
        padded_data,
        methods=pos_pad,  # the list of methods used sequentially
        output_shape=finalshape,  # the output shape you want to work with
        verbose=verbose  # whether to print logs during the reference voxel search
    )  
    #print(array(det_ref)-array(pad_before),array(det_ref),array(pad_before))
    pos_pad_after_crop=array(det_ref)-array(pad_before)

    mean_step_x = np.mean(np.diff(x))
    mean_step_y = np.mean(np.diff(y))
    mean_step_z = np.mean(np.diff(z))
    
    # Define the new coordinate ranges based on final shape and mean steps
    start_x = x[pos_pad_after_crop[0]] - ((roi[1] -roi[0] )//2)* mean_step_x
    end_x = start_x + finalshape[0] * mean_step_x
    new_x_crop = np.linspace(start_x, end_x, finalshape[0])
    
    start_y = y[pos_pad_after_crop[1]] - ((roi[3] -roi[2] )//2) * mean_step_y
    end_y = start_y + finalshape[1] * mean_step_y
    new_y_crop = np.linspace(start_y, end_y, finalshape[1])
    
    start_z = z[pos_pad_after_crop[2]] - ((roi[5] -roi[4] )//2) * mean_step_z
    end_z = start_z + finalshape[2] * mean_step_z
    new_z_crop = np.linspace(start_z, end_z, finalshape[2])

    # Assertions to check if the cropping and coordinate adjustments are correct
    try:
        assert crop_data_cdi.shape == tuple(finalshape), "Cropped data shape doesn't match finalshape"
        assert len(new_x_crop) == finalshape[0] and len(new_y_crop) == finalshape[1] and len(new_z_crop) == finalshape[2], "Cropped coordinate array lengths don't match finalshape"
        
        new_com = cropped_det_ref
        assert all(np.abs(com - finalshape[i]//2) < 2 for i, com in enumerate(new_com)), "Center of mass is not near the center of the new coordinate system"
    except AssertionError as e:
        logging.error(f"Assertion failed: {str(e)}")
        raise

    if verbose:
        print(f"Original shape: {data.shape}, Cropped shape: {crop_data_cdi.shape}")
        print(f"New coordinate ranges: x[{new_x_crop[0]:.2f}, {new_x_crop[-1]:.2f}], y[{new_y_crop[0]:.2f}, {new_y_crop[-1]:.2f}], z[{new_z_crop[0]:.2f}, {new_z_crop[-1]:.2f}]")
    
    return crop_data_cdi, new_x_crop, new_y_crop, new_z_crop
def crop_3d_obj_pos_and_update_coordinates(obj, x, y, z, output_shape=(100,100,100), pos="com", k_add=20, verbose=False):
    density = np.abs(obj)
    phase = np.angle(obj)
    
    orig_shape = np.array(obj.shape)
    output_shape = np.array(output_shape)
    
    
    if pos == "com":
        pos = np.array([int(np.round(i)) for i in C_O_M(density)])
    elif pos == "max":
        pos = np.array([int(np.round(i)) for i in np.where(density == density.max())])
    else:
        pos = np.array(pos)
    # Calculate padding
    k_add=20
    pad_before = np.maximum(output_shape // 2 - pos, 0)+k_add
    pad_after = np.maximum((pos + output_shape // 2 + output_shape % 2) - orig_shape, 0)+k_add
    
    # Pad the data
    padded_density = np.pad(density, list(zip(pad_before, pad_after)), mode='constant', constant_values=0)
    padded_phase = np.pad(phase, list(zip(pad_before, pad_after)), mode='constant', constant_values=0)
    print(pad_before,pad_after)
    
    # Calculate cropping
    if pos == "com":
        new_pos = np.array([int(np.round(i)) for i in C_O_M(padded_density)])
    elif pos == "max":
        new_pos = np.array([int(np.round(i)) for i in np.where(padded_density == padded_density.max())])
    else:
        new_pos = pos + (pad_before)
    print(new_pos,pos + (pad_before))
    start = new_pos - (np.round(output_shape / 2)).astype(int)
    end = start + output_shape
    
    # Crop the padded data
    cropped_density = padded_density[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
    cropped_phase = padded_phase[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
    
    # Estimate mean steps
    mean_step_x = np.mean(np.diff(x))
    mean_step_y = np.mean(np.diff(y))
    mean_step_z = np.mean(np.diff(z))
    
    start_x,end_x=x[pos[0]] - (pad_before[0]+pos[0]) * mean_step_x, x[pos[0]] + (pad_after[0]+orig_shape[0]-pos[0]) * mean_step_x
    start_y,end_y=y[pos[1]] - (pad_before[1]+pos[1]) * mean_step_y, y[pos[1]] + (pad_after[1]+orig_shape[1]-pos[1]) * mean_step_y
    start_z,end_z=z[pos[2]] - (pad_before[2]+pos[2]) * mean_step_z, z[pos[2]] + (pad_after[2]+orig_shape[2]-pos[2]) * mean_step_z
    
    # Update and extend coordinates
    new_x = np.arange(start_x,end_x, mean_step_x)
    new_y = np.arange(start_y,end_y, mean_step_y)
    new_z = np.arange(start_z,end_z, mean_step_z)

    
    new_x_crop = new_x[start[0]:end[0]]
    new_y_crop = new_y[start[1]:end[1]]
    new_z_crop = new_z[start[2]:end[2]]
    
    # Reconstruct the cropped complex object
    cropped_obj = cropped_density * np.exp(1j * cropped_phase)
    try:
        assert cropped_obj.shape == tuple(output_shape), "Cropped object shape doesn't match output_shape"
        assert len(new_x_crop) == output_shape[2] and len(new_y_crop) == output_shape[1] and len(new_z_crop) == output_shape[0], "Cropped coordinate array lengths don't match output_shape"
        
        if pos == "com":
            new_com = C_O_M(np.abs(cropped_obj))
            assert all(np.abs(com - output_shape[i]//2) < 2 for i, com in enumerate(new_com)), "Center of mass is not near the center of the new coordinate system"
        elif pos == "max":
            new_max = np.unravel_index(np.argmax(np.abs(cropped_obj)), cropped_obj.shape)
            assert all(np.abs(m - output_shape[i]//2) < 2 for i, m in enumerate(new_max)), "Maximum value is not near the center of the new coordinate system"
    except AssertionError as e:
        logging.error(f"Assertion failed: {str(e)}")
        raise

    if verbose:
        logging.info(f"Original shape: {obj.shape}, Cropped shape: {cropped_obj.shape}")
        logging.info(f"New coordinate ranges: x[{new_x_crop[0]:.2f}, {new_x_crop[-1]:.2f}], y[{new_y_crop[0]:.2f}, {new_y_crop[-1]:.2f}], z[{new_z_crop[0]:.2f}, {new_z_crop[-1]:.2f}]")

    return array(cropped_obj), new_x_crop, new_y_crop, new_z_crop
def crop_3d_obj_pos(obj, methods=["max", "com"], verbose=True, output_shape=(100, 100, 100)):
    """
    Crop complex 3D data around a specified position, with padding if necessary.

    Parameters:
    obj (numpy.ndarray): Complex 3D input array
    methods (list): Methods to determine the cropping center (e.g., ["max", "com"] or a specific position)
    verbose (bool): Whether to print detailed information
    output_shape (tuple): Desired shape of the cropped output

    Returns:
    numpy.ndarray: Cropped complex 3D array
    """
    density = np.abs(obj)
    phase = 0.0 - np.angle(np.exp(1j * np.angle(obj)))
    type_of_methods=check_type(methods)           
          
    if (("float" in type_of_methods)  or ("int" in type_of_methods)):
        # Handle cropping based on a specified position
        if verbose:
            print(f"Will crop around the specified position: {methods}")
        # Use the updated crop_3darray_pos for density and phase separately
        density = crop_3darray_pos(
            density,
            output_shape=output_shape,
            methods=methods,
            verbose=verbose,
        )
        phase = crop_3darray_pos(
            phase,
            output_shape=output_shape,
            methods=methods,
            verbose=verbose
        )

        # Reconstruct the cropped complex object
        obj = density * np.exp(1j * phase)

    else:
        # Use the updated crop_3darray_pos for density and phase separately
        det_ref, density = crop_3darray_pos(
            density,
            output_shape=output_shape,
            methods=methods,
            verbose=verbose,
            det_ref_return=True
        )
        phase = crop_3darray_pos(
            phase,
            output_shape=output_shape,
            methods=det_ref,
            verbose=verbose
        )

        # Reconstruct the cropped complex object
        obj = density * np.exp(1j * phase)
    
    return obj
def crop_3darray_pos_v00(data, output_shape=[100,100,100], methods=["max", "com"],verbose=True,det_ref_return=False):
    """
    Crop a 3D array around a specified position, with padding if necessary.
    
    Parameters:
    data (numpy.ndarray): 3D input array
    pos (tuple): Center position for cropping (z, y, x)
    output_shape (tuple): Desired shape of the output (z, y, x)
    
    Returns:
    numpy.ndarray: Cropped array of shape output_shape
    """
    # Ensure pos and output_shape are numpy arrays for easier manipulation
    if (('max' in methods ) or ('com' in methods)):
        pos=array([int(np.round(i)) for i in C_O_M(data)])
    else:
        pos=methods

    output_shape = np.array(output_shape)
    orig_shape=array(data.shape)
    k_add=10
    # Calculate padding
    pad_before = output_shape // 2 - pos 
    pad_after = np.maximum((pos + output_shape // 2 + output_shape % 2) - orig_shape, 0) + k_add
    pad_after=[i if i>0 else 0 for i in pad_after]
    pad_before=[i if i>0 else 0 for i in pad_before]
    # Pad the array
    padded_data = np.pad(data, list(zip(pad_before, pad_after)), mode='constant', constant_values=0)
    if not isinstance(methods, (np.ndarray, list, tuple)):
        if methods=='max': methods=['max']
        elif methods=='com': methods=['com']
    if (('max' in methods ) or ('com' in methods)):
        print('the methods choosed to centering is max or com or combination of both')
        (
            crop_data_cdi,  # the output cropped data
            det_ref,  # the detector reference voxel in the full detector frame
            cropped_det_ref,  # the detector reference voxel in the cropped detector frame
            roi  # the region of interest (ROI) used to crop the data
        ) = chain_centring(
            padded_data,
            methods=methods,  # the list of methods used sequentially
            output_shape=output_shape,  # the output shape you want to work with
            verbose=verbose  # whether to print logs during the reference voxel search
        )
    else:
        print('the origin of the crop is given by user ',methods)
        # Calculate crop indices
        start = methods - output_shape // 2
        end = start + output_shape
        print(start,end)
        # Crop the padded array
        crop_data_cdi = padded_data[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
        
    if det_ref_return:
        return det_ref,crop_data_cdi
    else:
        return crop_data_cdi
def crop_3darray_pos(data, output_shape=[100,100,100], methods=["max", "com"],verbose=True,det_ref_return=False):
    """
    Crop a 3D array around a specified position, with padding if necessary.
    
    Parameters:
    data (numpy.ndarray): 3D input array
    pos (tuple): Center position for cropping (z, y, x)
    output_shape (tuple): Desired shape of the output (z, y, x)
    
    Returns:
    numpy.ndarray: Cropped array of shape output_shape
    """
    # Ensure pos and output_shape are numpy arrays for easier manipulation
    if (('max' in methods ) or ('com' in methods)):
        pos=array([int(np.round(i)) for i in C_O_M(data)])
    else:
        pos=methods

    output_shape = np.array(output_shape)
    orig_shape=array(data.shape)
    k_add=10
    # Calculate padding
    pad_before = output_shape // 2 - pos 
    pad_after = np.maximum((pos + output_shape // 2 + output_shape % 2) - orig_shape, 0) + k_add
    print(pad_before)
    print(pad_after)
    pad_after=[i if i>0 else 0 for i in pad_after]
    pad_before=[i if i>0 else 0 for i in pad_before]
    # Pad the array
    padded_data = np.pad(data, list(zip(pad_before, pad_after)), mode='constant', constant_values=0)
    type_of_methods=check_type(methods)
    if type_of_methods=="str":      
        if methods=='max': methods=('max',)
        elif methods=='com': methods=('com',)
    elif ((type_of_methods=="array of float") or (type_of_methods=="array of int")):
            methods=(tuple(methods),)
    elif ((type_of_methods=="tuple of float") or (type_of_methods=="tuple of int")):
            methods=(tuple(methods),)
    elif ((type_of_methods=="list of float") or (type_of_methods=="list of int")):
            methods=(tuple(methods),)
    elif "mixed" in type_of_methods:
        if (("list" in  type_of_methods) or ("array" in  type_of_methods) ):
            methods=(tuple(methods),)    
            
        
        
    #print(check_type(methods),methods)
    (
        crop_data_cdi,  # the output cropped data
        det_ref,  # the detector reference voxel in the full detector frame
        cropped_det_ref,  # the detector reference voxel in the cropped detector frame
        roi  # the region of interest (ROI) used to crop the data
    ) = chain_centring(
        padded_data,
        methods=methods,  # the list of methods used sequentially
        output_shape=output_shape,  # the output shape you want to work with
        verbose=verbose  # whether to print logs during the reference voxel search
    )

    if det_ref_return:
        return det_ref,crop_data_cdi
    else:
        return crop_data_cdi
def transform_data_paraview_style(data, angle_x, angle_y, angle_z, padding_factor=1.5):
    
    """
    Transform a 3D numpy array using rotation angles in a way similar to ParaView,
    with padding to avoid data loss at edges.
    
    :param data: 3D numpy array of any shape
    :param angle_x: Rotation angle around x-axis in degrees
    :param angle_y: Rotation angle around y-axis in degrees
    :param angle_z: Rotation angle around z-axis in degrees
    :param padding_factor: Factor by which to increase the grid size (default: 1.5)
    :return: Transformed 3D numpy array of the same shape as input
    """
    original_shape = data.shape
    
    # Pad the data
    pad_width = tuple((int(s * (padding_factor - 1) / 2),) * 2 for s in original_shape)
    padded_data = np.pad(data, pad_width, mode='constant', constant_values=0)
    padded_shape = padded_data.shape
    
    # Convert angles to radians
    angle_x, angle_y, angle_z = np.radians([angle_x, angle_y, angle_z])
    
    # Create rotation matrices
    Rx = np.array([[1, 0, 0],
                   [0, np.cos(angle_x), -np.sin(angle_x)],
                   [0, np.sin(angle_x), np.cos(angle_x)]])

    Ry = np.array([[np.cos(angle_y), 0, np.sin(angle_y)],
                   [0, 1, 0],
                   [-np.sin(angle_y), 0, np.cos(angle_y)]])

    Rz = np.array([[np.cos(angle_z), -np.sin(angle_z), 0],
                   [np.sin(angle_z), np.cos(angle_z), 0],
                   [0, 0, 1]])

    # Combine rotations (order: Z, Y, X)
    R = Rx @ Ry @ Rz

    # Create coordinate grid for padded shape
    x, y, z = np.meshgrid(np.arange(padded_shape[0]), np.arange(padded_shape[1]), np.arange(padded_shape[2]), indexing='ij')
    coords = np.stack((x, y, z), axis=-1).reshape(-1, 3)

    # Center coordinates
    center = np.array([(s - 1) / 2 for s in padded_shape])
    coords_centered = coords - center

    # Apply rotation
    rotated_coords = (R @ coords_centered.T).T + center

    # Interpolate
    interpolator = RegularGridInterpolator((np.arange(padded_shape[0]), np.arange(padded_shape[1]), np.arange(padded_shape[2])), 
                                           padded_data, bounds_error=False, fill_value=0)
    transformed_data = interpolator(rotated_coords).reshape(padded_shape)

    # Crop back to original size
    start = tuple(int((ps - os) / 2) for ps, os in zip(padded_shape, original_shape))
    end = tuple(s + os for s, os in zip(start, original_shape))
    transformed_data = transformed_data[start[0]:end[0], start[1]:end[1], start[2]:end[2]]

    return transformed_data
def crop_3darray_pos_old(data, finalshape, pos="com"):
    
    """
    Crop a 3D array around a specified position, with padding if necessary.
    
    Parameters:
    data (numpy.ndarray): 3D input array
    pos (tuple): Center position for cropping (z, y, x)
    finalshape (tuple): Desired shape of the output (z, y, x)
    
    Returns:
    numpy.ndarray: Cropped array of shape finalshape
    """
    # Ensure pos and finalshape are numpy arrays for easier manipulation
    if pos=="com":
        pos=array([int(np.round(i)) for i in C_O_M(data)])
    elif pos=="max":
        pos=array([int(np.round(i)) for i in np.where(data==nanmax(data))[0]])
    else:
        pos = np.array(pos)
    finalshape = np.array(finalshape)
    orig_shape=array(data.shape)
    k_add=10
    # Calculate padding
    pad_before = finalshape // 2 - pos 
    pad_after = np.maximum((pos + finalshape // 2 + finalshape % 2) - orig_shape, 0) + k_add
    pad_after=[i if i>0 else 0 for i in pad_after]
    pad_before=[i if i>0 else 0 for i in pad_before]
    print(pad_before)
    # Pad the array
    padded_data = np.pad(data, list(zip(pad_before, pad_after)), mode='constant', constant_values=0)
    plot_3D_projections(zero_to_nan(padded_data),log_scale=True,cmap='jet',)
    
    # Adjust position for padded array

    if pos=="com":
        new_pos=array([int(np.round(i)) for i in C_O_M(padded_data)])
    elif pos=="max":
        new_pos=array([int(np.round(i)) for i in np.where(padded_data==nanmax(padded_data))[0]])
    else:
        new_pos = pos + pad_before
    
    # Calculate crop indices
    start = new_pos - finalshape // 2
    end = start + finalshape
    print(start,end)
    # Crop the padded array
    cropped = padded_data[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
    
    return cropped
def mask_clusters(data, threshold_factor=0.2, dilation_iterations=20, return_second_cluster=False):
    
    """
    Mask the cluster with the highest maximum value (or second highest if specified) and its surrounding region in 3D data.
    
    Parameters:
    data (numpy.ndarray): 3D input data
    threshold_factor (float): Factor to determine the threshold (default: 0.2)
    dilation_iterations (int): Number of iterations for mask dilation (default: 20)
    return_second_cluster (bool): Whether to return the second highest cluster instead of the first (default: False)
    
    Returns:
    tuple: (masked_data, data_after_masking, dilated_mask)
        masked_data: MaskedArray where the selected cluster and surroundings are unmasked
        data_after_masking: Original data with the selected cluster and surroundings set to zero
        dilated_mask: Boolean mask of the identified region
    """
    
    # Step 1: Find first global maximum
    max_value1 = np.max(data)
    max_coords1 = np.unravel_index(np.argmax(data), data.shape)

    # Step 2: Identify first cluster containing maximum
    threshold = max_value1 * threshold_factor
    binary = data > threshold
    labeled, num_features = ndimage.label(binary)
    max_label1 = labeled[max_coords1]

    # Step 3: Create mask for first cluster and surrounding region
    cluster_mask1 = labeled == max_label1
    dilated_mask1 = ndimage.binary_dilation(cluster_mask1, iterations=dilation_iterations)

    # Step 4: Apply mask to original data
    masked_data1 = np.ma.array(data, mask=~dilated_mask1)
    data_after_first_mask = data * (1 - dilated_mask1)

    if not return_second_cluster:
        return masked_data1, data_after_first_mask, dilated_mask1

    # If second cluster is requested, continue processing
    # Step 5: Find second global maximum
    max_value2 = np.max(data_after_first_mask)
    max_coords2 = np.unravel_index(np.argmax(data_after_first_mask), data.shape)

    # Step 6: Identify second cluster containing maximum
    threshold2 = max_value2 * threshold_factor
    binary2 = data_after_first_mask > threshold2
    labeled2, num_features2 = ndimage.label(binary2)
    max_label2 = labeled2[max_coords2]

    # Step 7: Create mask for second cluster and surrounding region
    cluster_mask2 = labeled2 == max_label2
    dilated_mask2 = ndimage.binary_dilation(cluster_mask2, iterations=dilation_iterations)

    # Step 8: Apply masks to original data
    masked_data2 = np.ma.array(data, mask=~dilated_mask2)
    data_after_masking = data * (1 - dilated_mask2)

    return masked_data2, data_after_masking, dilated_mask2



#%%data processing
def data_processing(files,dirlist):
    data_allscans_LLK,data_allscans_runs,data_allscans_rho ,data_allscans_phi , data_allscans_runs_meanz_rho,data_allscans_runs_meanz_phi ,data_allscans_mask ,data_allscans_COM  = {},{},{},{},{},{},{} , {}
    rho_min = 1
    for dir_ in range(len(dirlist)):
        start = time.time()
        data_run_nb,LLK_runs,rho_data,phi_data,i_COM,rho_data_cut,phi_data_cut,data_run_meanz_rho,data_run_meanz_phi = [],[],[],[],[],[],[],[],[]
        size = len(files[dir_])
        scan_nb = files[dir_][0][files[dir_][0].find('results/S') + 9:files[dir_][0].find('results/S') + 12]
        print('********** scan ' + str(scan_nb) + ' with ' + str(len(files[dir_])) + 'runs' + '**********')
        data_run_nb = [ int(IfStringRepresentsFloat(i[i.find('Run') + 3:i.find('Run') + 8])) for i in files[dir_] ]
        LLK_runs = [ IfStringRepresentsFloat(i[i.find('LLKf') + 16:i.find('LLKf') + 27]) for i in files[dir_] ]

        rho_data = [np.abs(np.array(np.load(i)['obj'])) for i in files[dir_]]
        phi_data = [np.angle(np.array(np.load(i)['obj'])) for i in files[dir_]]
        #phi_data = [np.mod(np.angle(np.array(np.load(i)['obj']),deg=True), 2*180) for i in files[dir_]]
        rho_data_mask = np.asarray(rho_data) * 0
        for i in range(len(rho_data)):        rho_data_mask[i][np.where(rho_data[i] > rho_min)] = 1
        i_COM = [ np.asarray(C_O_M(rho_data_mask[i])) for i in range(len(files[dir_])) ]
        i_COM = [list(map(int, i_COM[i])) for i in range(len(i_COM))]
        rho_data_mask = [ rho_data_mask[i][i_COM[i][0] - 39:i_COM[i][0] + 40, i_COM[i][1] - 50:i_COM[i][1] + 50, i_COM[i][2] - 50:i_COM[i][2] + 50]                     for i in range(len(i_COM)) ]
        rho_data_cut =  [ rho_data[i][i_COM[i][0]      - 39:i_COM[i][0] + 40, i_COM[i][1] - 50:i_COM[i][1] + 50, i_COM[i][2] - 50:i_COM[i][2] + 50] *  rho_data_mask[i] for i in range(len(i_COM))  ]
        phi_data_cut = [  phi_data[i][i_COM[i][0]      - 39:i_COM[i][0] + 40, i_COM[i][1] - 50:i_COM[i][1] + 50, i_COM[i][2] - 50:i_COM[i][2] + 50] *  rho_data_mask[i] for i in range(len(i_COM))  ]
        if len(rho_data_cut) == 0: continue
        i_COM = i_COM - 50 * np.asarray(i_COM)**0
        data_run_meanz_rho           = [ mean_z_run(rho_data_cut[i]) for i in range(len(i_COM)) ]
        data_run_meanz_phi           = [ mean_z_run(phi_data_cut[i]) for i in range(len(i_COM)) ]
        data_allscans_LLK            = { **data_allscans_LLK, str(scan_nb): np.asarray(LLK_runs) }
        data_allscans_runs           = { **data_allscans_runs, str(scan_nb): np.asarray(data_run_nb) }
        data_allscans_rho            = { **data_allscans_rho, str(scan_nb): np.asarray(rho_data_cut) }
        data_allscans_phi            = { **data_allscans_phi, str(scan_nb): np.asarray(phi_data_cut) }
        data_allscans_runs_meanz_rho = { **data_allscans_runs_meanz_rho, str(scan_nb): data_run_meanz_rho }
        data_allscans_runs_meanz_phi = { **data_allscans_runs_meanz_phi, str(scan_nb): data_run_meanz_phi }
        data_allscans_mask           = { **data_allscans_mask, str(scan_nb): np.asarray(rho_data_mask) }
        data_allscans_COM            = {**data_allscans_COM, str(scan_nb): np.asarray(i_COM)}
        end = time.time()
        print(str(int(((end - start) / 60) * 10) / 10) + 'min')
        #if dir_>=1: break
    return data_run_meanz_rho,data_run_meanz_phi,data_allscans_LLK,data_allscans_runs,data_allscans_rho,data_allscans_phi,data_allscans_runs_meanz_rho,data_allscans_runs_meanz_phi,data_allscans_mask,data_allscans_COM
#%% modes processing
def modes_processing(files,mypath='/home/abdelrahman/data_sixs_2019/'):
    final_selected_runs_allscsan={
        '100': [array([2, 4])],
        '103': [array([0, 6])],
        '113': [array([0, 1])],
        '400': [array([1, 4])],
        '439': [array([2, 3])],
        '657': [array([ 1, 16])],
        '668': [array([ 3, 19])],
        '671': [array([18, 22])]
                                 }
    ii_scan = 0
    data_allscans_runs_mode,data_allscans_rho_modes,data_allscans_phi_modes,data_allscans_mask_modes,data_allscans_COM_modes={}, {}, {}, {}, {}
    rho_min = 3
    for i_scan in final_selected_runs_allscsan.keys():
        start = time.time()
        data_run_nb ,rho_data,phi_data,i_COM,rho_data_cut,phi_data_cut = [], [], [], [], [], []
        destination_= [ mypath + 'S' + i_scan + '/selected_runs/'+str(i_run_list)+'/modes.h5' for i_run_list in range(len(final_selected_runs_allscsan[i_scan])) ]
        print('**********' + str(i_scan) + ' with ' + str(len(destination_)) + 'modes' + '**********')
        data_run_nb   = np.array([ i_run_list  for i_run_list in range(len(final_selected_runs_allscsan[i_scan])) ])
        rho_data      = np.array([np.abs(   np.array(h5py.File(f,'r+')['entry_1']['data_1']['data'][0] )) for f in destination_])
        phi_data      = np.array([np.angle( np.array(h5py.File(f,'r+')['entry_1']['data_1']['data'][0] )) for f in destination_])
        rho_data_mask = np.asarray(rho_data) * 0
        for i in range(len(rho_data)):             rho_data_mask[i][np.where(rho_data[i] > rho_min)] = 1
        i_COM = np.array([ np.asarray(C_O_M(rho_data_mask[i])) for i in range(len(destination_)) ])
        i_COM = np.array([list(map(int, i_COM[i])) for i in range(len(i_COM))])
        rho_data_mask = np.array([rho_data_mask[i][i_COM[i][0] - 39:i_COM[i][0] + 40, i_COM[i][1] - 50:i_COM[i][1] + 50, i_COM[i][2] - 50:i_COM[i][2] + 50]                   for i in range(len(i_COM)) ])
        rho_data_cut =  np.array([rho_data[i][i_COM[i][0]      - 39:i_COM[i][0] + 40, i_COM[i][1] - 50:i_COM[i][1] + 50, i_COM[i][2] - 50:i_COM[i][2] + 50] *rho_data_mask[i] for i in range(len(i_COM)) ])
        phi_data_cut =  np.array([phi_data[i][i_COM[i][0]      - 39:i_COM[i][0] + 40, i_COM[i][1] - 50:i_COM[i][1] + 50, i_COM[i][2] - 50:i_COM[i][2] + 50] *rho_data_mask[i] for i in range(len(i_COM)) ])
        if len(rho_data_cut) == 0: continue
        i_COM = i_COM - 50 * np.asarray(i_COM)**0

        data_allscans_runs_modes  =  {  **data_allscans_runs_mode, str(i_scan): np.asarray(data_run_nb)     }
        data_allscans_rho_modes   =  {  **data_allscans_rho_modes,  str(i_scan): np.asarray(rho_data_cut)   }
        data_allscans_phi_modes   =  {  **data_allscans_phi_modes,  str(i_scan): np.asarray(phi_data_cut)   }
        data_allscans_mask_modes  =  { **data_allscans_mask_modes,  str(i_scan): np.asarray(rho_data_mask)  }
        data_allscans_COM_modes   =  { **data_allscans_COM_modes,   str(i_scan): np.asarray(i_COM)          }
        end = time.time()
        print(str(int(((end - start) / 60) * 1000) / 1000) + 'min')
        ii_scan=ii_scan+1
    return final_selected_runs_allscsan,data_allscans_runs_modes,data_allscans_rho_modes,data_allscans_phi_modes,data_allscans_mask_modes,data_allscans_COM_modes
def runsmode_read(files_sel):
    scan_nb = np.array([str(int(IfStringRepresentsFloat(files_sel[dir_][0][files_sel[dir_][0].find('/S') + 2:files_sel[dir_][0].find('/S') + 6]))) for dir_ in range(len(files_sel.keys()))])
    ii_scan = 0
    data_allscans_rho_modes = {}
    data_allscans_phi_modes = {}
    data_allscans_data_complex_modes={}
    data_allscans_mask_modes={}
    for i_scan in scan_nb:
        start = time.time()
        data_complex = []
        rho_data = []
        phi_data = []
        destination_= files_sel[ii_scan]
        print('**********' + str(i_scan) + ' with ' + str(len(destination_)) + 'modes' + '**********')
        rho_data = np.array([np.abs(np.array(np.load(i)['obj'])) for i in destination_])
        phi_data = np.array([np.angle(np.array(np.load(i)['obj'])) for i in destination_])
        data_complex  = np.array([np.array(np.load(i)['obj']) for i in destination_])
        mask=np.asarray(rho_data)*0
        mask[np.where(rho_data>5)] = 1
        rho_data=rho_data*mask
        phi_data=phi_data*mask
        data_complex=data_complex*mask
        data_allscans_rho_modes                =  {  **data_allscans_rho_modes,  str(i_scan): np.asarray(rho_data)  }
        data_allscans_phi_modes                =  {  **data_allscans_phi_modes,  str(i_scan): np.asarray(phi_data)  }
        data_allscans_data_complex_modes       =  {  **data_allscans_data_complex_modes,  str(i_scan): np.asarray(data_complex) }
        data_allscans_mask_modes               =  {  **data_allscans_mask_modes        ,  str(i_scan): np.asarray(mask)}
        end = time.time()
        print(str(int(((end - start) ) * 1000) / 1000) + 'sec')
        ii_scan=ii_scan+1
    return data_allscans_rho_modes,data_allscans_phi_modes,data_allscans_data_complex_modes,data_allscans_mask_modes
def modes_read(mypath='/home/abdelrahman/data_sixs_2019/'):
    final_selected_runs_allscsan={
        '100': [array([2, 4])],
        '103': [array([0, 6])],
        '113': [array([0, 1])],
        '400': [array([1, 4])],
        '439': [array([2, 3])],
        '657': [array([ 1, 16])],
        '668': [array([ 3, 19])],
        '671': [array([18, 22])]
                                 }
    ii_scan = 0
    data_allscans_rho_modes = {}
    data_allscans_phi_modes = {}
    data_allscans_data_complex_modes={}
    data_allscans_mask_modes={}
    for i_scan in final_selected_runs_allscsan.keys():
        start = time.time()
        data_complex = []
        rho_data = []
        phi_data = []

        destination_= [ mypath + 'S' + i_scan + '/selected_runs/'+str(i_run_list)+'/modes.h5' for i_run_list in range(len(final_selected_runs_allscsan[i_scan])) ]
        print('**********' + str(i_scan) + ' with ' + str(len(destination_)) + 'modes' + '**********')
        rho_data      = np.array([np.abs(   np.array(h5py.File(f,'r+')['entry_1']['data_1']['data'][0] )) for f in destination_])
        phi_data      = np.array([np.angle( np.array(h5py.File(f,'r+')['entry_1']['data_1']['data'][0] )) for f in destination_])
        data_complex  = np.array([np.array(h5py.File(f,'r+')['entry_1']['data_1']['data'][0] ) for f in destination_])
        mask=np.asarray(rho_data)*0
        mask[np.where(rho_data>5)] = 1
        rho_data=rho_data*mask
        phi_data=phi_data*mask
        data_complex=data_complex*mask
        data_allscans_rho_modes                =  {  **data_allscans_rho_modes,  str(i_scan): np.asarray(rho_data)  }
        data_allscans_phi_modes                =  {  **data_allscans_phi_modes,  str(i_scan): np.asarray(phi_data)  }
        data_allscans_data_complex_modes       =  { **data_allscans_data_complex_modes,  str(i_scan): np.asarray(data_complex) }
        data_allscans_mask_modes               =  { **data_allscans_mask_modes        ,  str(i_scan): np.asarray(mask)}
        end = time.time()
        print(str(int(((end - start) ) * 1000) / 1000) + 'sec')
        ii_scan=ii_scan+1
    return final_selected_runs_allscsan,data_allscans_rho_modes,data_allscans_phi_modes,data_allscans_data_complex_modes,data_allscans_mask_modes

def get_dislocation_position(data_mask):
    shape_=data_mask.shape
    c= np.zeros(shape_)
    for x_i in range(shape_[0]):
        for y_i in range(shape_[1]):
            for z_i in range(2,shape_[2]):
                if data_mask[x_i,y_i,z_i-1]==0:
                    if data_mask[x_i,y_i,z_i]==0:  
                            c[x_i,y_i,z_i]=0
                    else:          
                        c[x_i,y_i,z_i] = 10
                else:
                    c[x_i,y_i,z_i] = 0
    for x_i in range(shape_[0]):
        for y_i in range(shape_[1]):
            for z_i in range(shape_[2]):
                if c[x_i,y_i,z_i]==10:
                    c[x_i,y_i,z_i]=0
                    break
                else:
                    continue
    dislo_positions=np.array(np.where(c!=0))
    #dislo_positions= np.array([ dislo_positions[i][(dislo_positions[0]==44) | (dislo_positions[0]==35)] for i in range(len(dislo_positions))])
    most_freq_z=np.bincount(dislo_positions[0]).argmax()
    dislo_positions= np.array([ dislo_positions[i][ (dislo_positions[0]==most_freq_z)] for i in range(len(dislo_positions)) ] )
    for i_index in range(len(dislo_positions[0])):
        if dislo_positions[0][i_index]!=most_freq_z:
            np.delete()
    return dislo_positions,c
def sum_z_run(data):
    sum_=data[0]
    for i in range(1,len(data)):
        sum_=sum_+ data[i]
        
    return sum_
def sum_y_run(data):
    sum_=data[:,0,:]
    for i in range(1,data.shape[1]):
        sum_=sum_+ data[:,i,:]     
    return sum_
def maxcorr_index(corr_data,shift_from_max,allowed_min):
    for i_scan in corr_data.keys():
        min_corr=np.max(corr_data[i_scan])-shift_from_max
        if min_corr < allowed_min: 
            print('scan '+str(i_scan) +'reconstruction problem. Runs are not well reconstructed.')
            continue
        corr_data[i_scan][np.where(max_corr[i_scan]==1)]=0
        index_best_run=np.array(np.sort(list(set(np.array(np.where(max_corr[i_scan]>min_corr)).flatten()))))
        
        n_frames=len(index_best_run)
        print('**********' + i_scan + ' with ' +str(n_frames)  +
              'selected runs' + '**********'+ 'max corr: '+ str(int(100*(min_corr+shift_from_max))))
        print(index_best_run)
def std_dltaphi(data_phi,data_mask):
    std_phi_allscan={}
    for i_scan in data_phi.keys():
        start = time.time()
        print('**********' + i_scan + ' with '+str(len(data_phi[i_scan])) + 'runs' + '**********')
        nb_frames = len(data_phi[i_scan])
        std_phi_run = np.zeros((nb_frames, nb_frames))
        for j_run in range(nb_frames):
            for i_run in range(j_run + 1):
                if i_run < j_run:
                    mask=data_mask[i_scan][j_run]*data_mask[i_scan][i_run]
                    len_eff= mask.sum()
                    delta_phi = np.angle(np.exp(1j * (data_phi[i_scan][j_run] -data_phi[i_scan][i_run])))*mask
                    mean_dphi = delta_phi.sum()/len_eff
                    std_phi_run[j_run,i_run]=  np.sqrt(np.square((delta_phi-mean_dphi)*mask).sum()/len_eff)
            std_phi_run[:, j_run] = std_phi_run[j_run, :]
            std_phi_run[j_run, j_run] = 7
        std_phi_allscan = {**std_phi_allscan, str(i_scan): std_phi_run}
        end = time.time()
        print(str(int(((end - start) / 60) * 10) / 10) + 'min')
    return std_phi_allscan
def dltaphi(data_phi,data_mask):
    nb_scan = len(data_phi)
    dphi_allscan = {}
    for i_scan in data_phi.keys():
        start = time.time()
        shape_data_=data_phi[i_scan][0].shape
        print('**********' + i_scan + ' with ' +
              str(len(data_phi[i_scan])) + 'runs' + '**********')
        nb_frames = len(data_phi[i_scan])
        delta_phi = np.zeros((nb_frames, nb_frames,shape_data_[0],shape_data_[1],shape_data_[2]))
        for j_run in range(nb_frames):
            for i_run in range(j_run + 1):
                    mask=data_mask[i_scan][j_run]
                    delta_phi[j_run,i_run] = np.angle(np.exp(1j * (data_phi[i_scan][j_run] -data_phi[i_scan][i_run])))*mask
                    #mean_dphi = delta_phi0.sum()/len(mask)
                    #delta_phi1 = np.angle(np.exp(1j * (data_phi[i_scan][j_run] -np.flip(data_phi[i_scan][i_run]))))*mask
                    #mean_dphi1 = delta_phi1.sum()/len(mask)
                    #if mean_dphi1<=mean_dphi0:
                    #    mean_dphi=mean_dphi1
                    #    delta_phi=delta_phi1
                    #else:
                    #    mean_dphi=mean_dphi0
                    #    delta_phi=delta_phi0  
        dphi_allscan = {**dphi_allscan, str(i_scan): delta_phi}
        end = time.time()
        print(str(int(((end - start) / 60) * 10) / 10) + 'min')
    return dphi_allscan
def std_rho(data_):
    nb_scan = len(data_)
    std_data_allscsans = {}
    mean_overy_data_allscsans={}
    mean_overz_data_allscsans={}
    for i_scan in data_.keys():
        start = time.time()
        print('**********' + i_scan + ' with ' +
              str(len(data_[i_scan])) + 'runs' + '**********')
        nb_frames = len(data_[i_scan])
        mean_overy_data_allruns = np.zeros((nb_frames,data_[i_scan][0].shape[0],data_[i_scan][0].shape[2] )  ) 
        mean_overz_data_allruns = np.zeros((nb_frames,data_[i_scan][0].shape[1],data_[i_scan][0].shape[2] )  )
        std_data_allruns = np.zeros((nb_frames))
        for j_run in range(nb_frames):
        ####### statistical information calculation:STD#############
                combined_data                  =  data_[i_scan][j_run].flatten()
                combined_data                  =  combined_data[np.where(combined_data !=0)]
                mean_data                      =  np.mean(combined_data)
                std_data_allruns[j_run]        =  std_data(combined_data)
                mean_overy_data_allruns[j_run] =  mean_y_run(data_[i_scan][j_run])
                mean_overz_data_allruns[j_run] =  mean_z_run(data_[i_scan][j_run])
                #std_data_allruns            = np.append(std_data_allruns, std_data_run)
                #mean_overy_data_allruns     = np.append(std_data_allruns, mean_y_run(data_[i_scan][j_run]))
                #if std_rho_data<=0.0145: 
                #    selected_runs=np.append(selected_runs,data_allscans_runs[i_scan][j_run])
        std_data_allscsans = {**std_data_allscsans, str(i_scan): std_data_allruns}
        mean_overy_data_allscsans={**mean_overy_data_allscsans, str(i_scan): mean_overy_data_allruns}
        mean_overz_data_allscsans={**mean_overz_data_allscsans, str(i_scan): mean_overz_data_allruns}
        end = time.time()
        print(str(int(end - start )) + 'sec')
    return std_data_allscsans,mean_overy_data_allscsans,mean_overz_data_allscsans
def flatten_dict_scan_list_run(dict_):
    if type(dict_)==dict:
        a=[ np.array(value) for value in np.array(list(dict_.items()),dtype=object)[:,1] ]
    else:
        a=dict_
    a= [item for sublist in a for item in sublist]

    return np.array(list(set(np.array(a))))

def get_sphere_intsum_mode(int_ortho_scan_cut_max,range_r,radius_step,plot_=False):
    center_ = (np.array(int_ortho_scan_cut_max.shape) / 2).astype(int)
    dim_x, dim_y, dim_z = center_
    frame = np.indices(int_ortho_scan_cut_max.shape)
    real_x_, real_y_, real_z_ = frame[0], frame[1], frame[2]
    theta, phi, r = xyz_to_thetaphir(real_x_ - int(dim_x),real_y_ - int(dim_x),real_z_ - int(dim_x))
    a, b = range_r
    intensity_sum = []
    for r_i in range(a, b, radius_step):
        circle_matrix = np.zeros(int_ortho_scan_cut_max.shape)
        bool_d = np.where(((r >= r_i - radius_step) & (r <= r_i)))
        circle_matrix[bool_d] = 1
        int_ortho_scan_ = circle_matrix * int_ortho_scan_cut_max
        intensity_sum = np.append(intensity_sum, np.mean(int_ortho_scan_[int_ortho_scan_ != 0]))
        if plot_:
            plotqxqyqzi_imshow(data__, str(r_i))
            plotqxqyqzi_imshow(data_, str(r_i))
    return intensity_sum
def get_max_or_com(ndata,off_set_y,max_or_com="com"):
        if max_or_com=="com":    
            try:
                com_=[int(i) for i in C_O_M(ndata)]
                com_[1]+=off_set_y
            except:
                com_=[0,0,0]            
            return com_
        else: 
            try:
                max_=[int(i) for i in np.where(ndata==ndata.max())]
                max_[1]+=off_set_y
            except:
                max_=[0,0,0]
            return max_ 
def load_reco_from_cxinpz(path,multiply_by_mask=False):
    """Load the specfile from the given path"""
    #  return silx.io.specfile.SpecFile(path)
    if (path[-3:]=='cxi') or (path[-2:]=='h5'):
        with silx.io.open(path) as specfile:
            data = specfile
            #data.visititems(print_item)
            int_=np.array(data["entry_1/image_1/data"])
        specfile.close()
        if multiply_by_mask: # for reconstructions if available
            mask=np.array(data["entry_1/image_1/mask"])
    if path[-3:]=='npz':
        int_=np.array(np.load(path)['obj'])
    if multiply_by_mask: 
        return int_*mask
    else:
        return int_
def get_max_cut_parametre(parametre,wanted_nb=25):
    to_sort_list=np.array(nan_to_zero(parametre))
    to_sort_list=to_sort_list[to_sort_list!=0]
    to_sort_list.sort()
    max_mtm=to_sort_list[wanted_nb]
    return max_mtm
def format_vector(vector, decimal_places=4):
    formatted = []
    for num in vector:
        num = float(num)
        rounded = round(num, decimal_places)
        if np.abs(rounded) < 0.001 or np.abs(rounded) >= 1000:
            str_num = f"{rounded:.{decimal_places}e}"
        else:
            str_num = f"{rounded:.{decimal_places}f}".rstrip('0').rstrip('.')
        formatted.append(str_num)
    return f"{', '.join(formatted)}"
def pad_to_shape(arr, target_shape, pad_value=0):
    # Calculate the difference in shape
    diff_shape = [(max(0, target_shape[i] - arr.shape[i])) for i in range(3)]

    # Calculate the padding for the beginning and the end
    pad_width = [(diff//2, diff-diff//2) for diff in diff_shape]

    # Pad the array
    padded_arr = np.pad(arr, pad_width, mode='constant', constant_values=pad_value)

    return padded_arr

def optimize_cropping(data):
    """
    Optimize cropping around the center of mass (COM) while avoiding zero cropping.

    Parameters:
    - data (numpy.ndarray): 3D array of shape (z, y, x).

    Returns:
    - crop_width (int): Maximum width for cropping in any direction.
    """

    # Calculate sum along each direction
    sum_z = np.sum(data, axis=(1, 2))
    sum_y = np.sum(data, axis=(0, 2))
    sum_x = np.sum(data, axis=(0, 1))

    # Find the index of the first and last non-zero elements
    first_nonzero_z = np.argmax(sum_z > 0)
    last_nonzero_z = len(sum_z) - np.argmax(sum_z[::-1] > 0) - 1
    first_nonzero_y = np.argmax(sum_y > 0)
    last_nonzero_y = len(sum_y) - np.argmax(sum_y[::-1] > 0) - 1
    first_nonzero_x = np.argmax(sum_x > 0)
    last_nonzero_x = len(sum_x) - np.argmax(sum_x[::-1] > 0) - 1

    # Calculate crop width for each direction
    crop_width_z = max(last_nonzero_z - first_nonzero_z + 1, 0)
    crop_width_y = max(last_nonzero_y - first_nonzero_y + 1, 0)
    crop_width_x = max(last_nonzero_x - first_nonzero_x + 1, 0)

    # Return the maximum crop width among the three directions
    return max(crop_width_z, crop_width_y, crop_width_x)
def get_size_3D_pixel(data):
    """
    Calculate the maximum width for cropping in any direction based on the non-zero elements along each axis.

    Parameters:
    - data (numpy.ndarray): 3D array of shape (z, y, x).

    Returns:
    - crop_width (tuple): Maximum width for cropping in each direction (z, y, x).
    """

    # Calculate sum along each direction
    sum_z = np.sum(data, axis=(1, 2))
    sum_y = np.sum(data, axis=(0, 2))
    sum_x = np.sum(data, axis=(0, 1))

    # Find the index of the first and last non-zero elements
    first_nonzero_z = np.argmax(sum_z > 0)
    last_nonzero_z = len(sum_z) - np.argmax(sum_z[::-1] > 0) - 1
    first_nonzero_y = np.argmax(sum_y > 0)
    last_nonzero_y = len(sum_y) - np.argmax(sum_y[::-1] > 0) - 1
    first_nonzero_x = np.argmax(sum_x > 0)
    last_nonzero_x = len(sum_x) - np.argmax(sum_x[::-1] > 0) - 1

    # Calculate crop width for each direction
    crop_width_z = max(last_nonzero_z - first_nonzero_z + 1, 0)
    crop_width_y = max(last_nonzero_y - first_nonzero_y + 1, 0)
    crop_width_x = max(last_nonzero_x - first_nonzero_x + 1, 0)

    # Return the maximum crop width among the three directions
    return (crop_width_z, crop_width_y, crop_width_x)
    
def fit_model_regression(method, X, y, **kwargs):
    """
    Fit a regression model specified by the method.

    Parameters:
    - method (str): The name of the method to use for fitting the model.
    - X (array-like): Input features.
    - y (array-like): Target variable.
    - **kwargs: Additional keyword arguments to pass to the model constructor.

    Returns:
    - model: Fitted regression model.
    - predictions: Predictions made by the model.
    """
    if method == "LinearRegression":
        model = LinearRegression(**kwargs)
    elif method == "RandomForestRegressor":
        model = RandomForestRegressor(**kwargs)
    elif method == "DecisionTreeRegressor":
        model = DecisionTreeRegressor(**kwargs)
    elif method == "KNeighborsRegressor":
        model = KNeighborsRegressor(**kwargs)
    elif method == "SVR":
        model = SVR(**kwargs)
    elif method == "MLPRegressor":
        model = MLPRegressor(**kwargs)
    else:
        raise ValueError("Invalid method specified. Supported methods: LinearRegression, RandomForestRegressor, DecisionTreeRegressor, KNeighborsRegressor, SVR, MLPRegressor.")
    
    # Fit the model
    model.fit(X, y)

    # Make predictions
    predictions = model.predict(X)

    return model, predictions

